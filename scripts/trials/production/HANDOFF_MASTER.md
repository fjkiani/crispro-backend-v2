# üéØ PRODUCTION HANDOFF - MASTER DOCUMENT

**Date:** January 2026  
**Status:** Handoff from Zo (Trials Agent) to JR3/Alpha  
**Purpose:** Single source of truth for all production work and remaining tasks

---

## üìã EXECUTIVE SUMMARY

### **What's Complete** ‚úÖ
- Production infrastructure organized (4 core agents: Discovery, Refresh, Tagging, Matching)
- Critical bugs fixed (DB_PATH, query generation, discovery data preservation, CT.gov API, vector storage)
- Unified pipeline created (`run_pipeline.py`)
- Holistic score integration complete
- Vector storage fixed (AstraDB batch insert_many pattern) ‚úÖ
- Documentation consolidated

### **What Needs Work** ‚ö†Ô∏è
- **P0 (CRITICAL):** End-to-end testing (backend endpoints may be hanging)
- **P1 (HIGH):** Automation (schedulers for refresh, tagging, sync)
- **P2 (MEDIUM):** Increase MoA coverage (42% ‚Üí 70%+)
- **P3 (ONGOING):** Backend endpoint debugging and optimization

### **Current State**
- **Trials Database:** 1,397 trials in SQLite
- **MoA Coverage:** 585 trials tagged (42%)
- **Backend Status:** ‚ö†Ô∏è **UNTESTED** - Endpoints may be hanging (see CRITICAL ISSUES section)

---

## üìÅ DIRECTORY STRUCTURE (COMPLETE)

```
scripts/trials/
‚îú‚îÄ‚îÄ production/                    # ‚öîÔ∏è Production Infrastructure
‚îÇ   ‚îú‚îÄ‚îÄ run_discovery.py          # Entry point: Discovery (Concern A)
‚îÇ   ‚îú‚îÄ‚îÄ run_refresh.py            # Entry point: Refresh (Concern B)
‚îÇ   ‚îú‚îÄ‚îÄ run_tagging.py            # Entry point: Tagging (Concern C)
‚îÇ   ‚îú‚îÄ‚îÄ run_matching.py           # Entry point: Matching (Concern D)
‚îÇ   ‚îú‚îÄ‚îÄ run_pipeline.py           # Unified pipeline (fetch ‚Üí save ‚Üí tag ‚Üí sync)
‚îÇ   ‚îú‚îÄ‚îÄ core/                     # Core agent modules
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ discovery_agent.py   # ‚úÖ Complete
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ refresh_agent.py     # ‚úÖ Complete
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tagging_agent.py     # ‚úÖ Complete
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ matching_agent.py    # ‚úÖ Complete (with holistic score)
‚îÇ   ‚îî‚îÄ‚îÄ HANDOFF_MASTER.md         # This document
‚îÇ
‚îú‚îÄ‚îÄ utilities/                     # üîß Utility Scripts
‚îÇ   ‚îú‚îÄ‚îÄ seed_astradb_from_sqlite.py
‚îÇ   ‚îú‚îÄ‚îÄ seed_trials_table.py
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ archive/                       # üì¶ Consolidated/Obsolete Files
‚îÇ   ‚îî‚îÄ‚îÄ (old scripts moved here)
‚îÇ
‚îî‚îÄ‚îÄ PRODUCTION_STRUCTURE.md        # Main documentation
```

---

## ‚úÖ COMPLETED WORK

### **1. Core Infrastructure** ‚úÖ COMPLETE

#### **Concern A: Candidate Discovery** (`core/discovery_agent.py`)
- ‚úÖ SQLite corpus discovery (200-1000 candidates)
- ‚úÖ AstraDB semantic search (Cohere embeddings)
- ‚úÖ CT.gov fallback
- ‚úÖ Profile format handling (nested + flat)
- ‚úÖ Query generation with fallback (always produces at least 1 query)
- **Entry Point:** `production/run_discovery.py`

#### **Concern B: Refresh** (`core/refresh_agent.py`)
- ‚úÖ 24h SLA with `last_refreshed_at` tracking
- ‚úÖ Staleness detection and warnings
- ‚úÖ Incremental refresh queues
- ‚úÖ Bounded refresh on login (top K trials)
- ‚úÖ CT.gov API fixes (NCT ID validation, batch limits, URL length)
- **Entry Point:** `production/run_refresh.py`

#### **Concern C: Offline Tagging** (`core/tagging_agent.py`)
- ‚úÖ MoA vector enrichment (585 trials tagged)
- ‚úÖ 7D mechanism vectors: [DDR, MAPK, PI3K, VEGF, HER2, IO, Efflux]
- ‚úÖ Incremental tagging with checksums
- ‚úÖ Automated QA
- **Entry Point:** `production/run_tagging.py`

#### **Concern D: Patient Matching + Dossier** (`core/matching_agent.py`)
- ‚úÖ Hard filtering (stage, treatment line, recruiting, location)
- ‚úÖ Eligibility checklists (hard/soft criteria)
- ‚úÖ Mechanism fit ranking (if SAE vector provided)
- ‚úÖ **Holistic Score Integration** (NEW)
  - Formula: `(0.5 √ó Mechanism Fit) + (0.3 √ó Eligibility) + (0.2 √ó PGx Safety)`
  - PGx Safety Gate integrated
  - Contraindication detection (DPYD, TPMT, UGT1A1 variants)
- ‚úÖ Discovery data preservation (status from discovery preserved)
- ‚úÖ Drug name parsing for PGx screening
- **Entry Point:** `production/run_matching.py`

### **2. Critical Bugs Fixed** ‚úÖ COMPLETE

#### **Fix 1: DB_PATH Calculation** ‚úÖ
- **Problem:** `BACKEND_ROOT = SCRIPT_DIR.parent.parent.parent` went too far
- **Fix:** Changed to `parent.parent` (correct: oncology-backend-minimal/)
- **File:** `production/core/discovery_agent.py` line 54

#### **Fix 2: Autonomous Agent Fallback** ‚úÖ
- **Problem:** Autonomous agent returned empty queries `[]` with no fallback
- **Fix:** Added fallback logic - always produces at least "cancer clinical trial" query
- **File:** `production/core/discovery_agent.py` lines 157-174

#### **Fix 3: Discovery Result Handling** ‚úÖ
- **Problem:** Discovery result format not handled correctly (str vs dict error)
- **Fix:** Handle both dict and list formats, robust format detection
- **File:** `production/core/matching_agent.py` lines 170-203

#### **Fix 4: Discovery Data Preservation** ‚úÖ **CRITICAL**
- **Problem:** Trial status from discovery was being lost when refresh failed
- **Root Cause:** Matching agent only used NCT IDs, ignored full candidate objects
- **Fix:** Use discovery candidates as fallback when refresh fails
- **File:** `production/core/matching_agent.py` lines 166-270
- **Impact:** Trial status now preserved from discovery even if CT.gov refresh fails

#### **Fix 5: CT.gov API 400 Errors** ‚úÖ
- **Problems:**
  1. Invalid/empty NCT IDs
  2. Batch size too large (>100 per request)
  3. URL length too long (>5000 chars)
  4. Missing error logging
- **Fixes Applied:**
  - NCT ID validation & cleaning (strip, upper, validate format)
  - Batch size enforcement (MAX_NCT_IDS_PER_REQUEST = 100)
  - URL length handling (split into chunks if >5000 chars)
  - Detailed error logging (400 error details + retry with single ID)
- **File:** `api/services/trial_refresh/api_client.py` (lines 57-165)

#### **Fix 6: Profile Format Mismatch** ‚úÖ
- **Problem:** Discovery agent expected nested format but holistic score sent flat format
- **Fix:** Added `_extract_profile_field()` helper that handles both formats
- **File:** `production/core/discovery_agent.py`

#### **Fix 7: Entry Point Broken** ‚úÖ
- **Problem:** `run_matching.py` didn't work from its own directory due to path issues
- **Fix:** Added proper path resolution, error handling
- **File:** `production/run_matching.py`

#### **Fix 8: Vector Storage in AstraDB** ‚úÖ
- **Problem:** Vectors not stored correctly in AstraDB (using `replace_one`/`find_one_and_replace`)
- **Fix:** Changed to batch `insert_many` pattern (matching working examples)
- **File:** `utilities/seed_astradb_from_sqlite.py`
- **Status:** ‚úÖ Vector storage working, vector search confirmed functional
- **Current State:** 29/30 trials synced from `clinical_trials` table (Ayesha's curated ovarian cancer trials)
- **Note:** Script uses `clinical_trials` table (30 curated trials), not `trials` table (1,397 mixed/completed trials)
- **Known Issue:** OpenAI embeddings are 1536-dim but collection uses 768-dim (truncated automatically)
- **Details:** See `utilities/VECTOR_STORAGE_FIX_COMPLETE.md` for full documentation

### **3. Unified Pipeline** ‚úÖ COMPLETE

**File:** `production/run_pipeline.py`

**Usage:**
```bash
python run_pipeline.py --disease "ovarian cancer" --count 500 --tag --sync
```

**What It Does:**
1. ‚úÖ Fetches trials from CT.gov API
2. ‚úÖ Dedupes against existing SQLite trials
3. ‚úÖ Saves new trials to SQLite (correct schema)
4. ‚úÖ Tags new trials for MoA (if --tag flag)
5. ‚úÖ Syncs new trials to AstraDB (if --sync flag)

**Status:** ‚úÖ **CREATED** - Ready for testing

---

## üî¥ CRITICAL ISSUES (UNTESTED)

### **Backend Endpoints May Be Hanging** ‚ùå **REQUIRES IMMEDIATE TESTING**

**Status:** ‚ö†Ô∏è **NOT TESTED** - Endpoints may be hanging/unresponsive

**Affected Endpoints:**
1. `GET /api/health` - May timeout
2. `POST /api/complete_care/v2` - May hang on button click
3. `POST /api/trials/agent/search` - May hang on search
4. `POST /api/ayesha/complete_care_v2` - May hang on button click

**Possible Causes:**
- Backend hung on startup (import errors, missing dependencies)
- Database connections hanging (Supabase/AstraDB/SQLite)
- Nested HTTP calls timing out
- Missing timeouts on nested calls

**Diagnosis Steps (TO DO):**
```bash
# Step 1: Check if backend is running
curl http://localhost:8000/api/health
# Should return: {"status": "healthy"}

# Step 2: Check uvicorn process
ps aux | grep uvicorn
lsof -i :8000

# Step 3: Test import errors
cd oncology-backend-minimal
python3 -c "from api.main import app; print('‚úÖ Imports OK')"

# Step 4: Test endpoints individually
curl -X POST http://localhost:8000/api/complete_care/v2 \
  -H "Content-Type: application/json" \
  -d '{"patient_profile":{"disease":"ovarian_cancer_hgs"}}' \
  --max-time 30

curl -X POST http://localhost:8000/api/trials/agent/search \
  -H "Content-Type: application/json" \
  -d '{"query":"ovarian cancer"}' \
  --max-time 30
```

**If Endpoints Fail:**
- Check backend logs for errors
- Verify database connections (Supabase/AstraDB/SQLite)
- Add timeouts to nested HTTP calls (5-10s max per service)
- Make endpoints fail fast (return partial results if some services fail)

---

## üìã REMAINING WORK (PRIORITY ORDER)

### **P0: CRITICAL - End-to-End Testing** üî¥ **DO FIRST**

**Status:** ‚ùå **NOT DONE** - **REQUIRES IMMEDIATE ATTENTION**

**Tasks:**
1. **Test Backend Health** ‚ö†Ô∏è **REQUIRED**
   ```bash
   curl http://localhost:8000/api/health
   ```
   - [ ] Backend responds to health check
   - [ ] If timeout: check backend logs, restart backend

2. **Test Unified Pipeline** ‚ö†Ô∏è **REQUIRED**
   ```bash
   cd oncology-coPilot/oncology-backend-minimal/scripts/trials/production
   python run_pipeline.py --disease "ovarian cancer" --count 10 --tag
   ```
   - [ ] Pipeline runs without errors
   - [ ] 10 new trials fetched from CT.gov
   - [ ] Trials deduped correctly
   - [ ] Trials saved to SQLite
   - [ ] Trials tagged with MoA vectors
   - [ ] Verify SQLite: `SELECT COUNT(*) FROM trials WHERE id IN (...)` 
   - [ ] Verify MoA vectors: Check `api/resources/trial_moa_vectors.json`

3. **Test Matching Agent** ‚ö†Ô∏è **REQUIRED**
   ```bash
   cd oncology-coPilot/oncology-backend-minimal/scripts/trials/production
   python run_matching.py
   ```
   - [ ] Matching agent runs without errors
   - [ ] At least 1 query generated (never 0)
   - [ ] Candidates discovered (200+ trials)
   - [ ] Holistic scores computed
   - [ ] Trials matched and returned (5+ trials)
   - [ ] Status preserved from discovery (not UNKNOWN)

4. **Test Backend Endpoints** ‚ö†Ô∏è **REQUIRED**
   ```bash
   # Test health endpoint
   curl http://localhost:8000/api/health
   
   # Test trials search
   curl -X POST http://localhost:8000/api/trials/agent/search \
     -H "Content-Type: application/json" \
     -d '{"query":"ovarian cancer","disease":"ovarian_cancer_hgs"}' \
     --max-time 30
   
   # Test complete care
   curl -X POST http://localhost:8000/api/complete_care/v2 \
     -H "Content-Type: application/json" \
     -d '{"patient_profile":{"disease":"ovarian_cancer_hgs","stage":"IVB"}}' \
     --max-time 30
   ```
   - [ ] All endpoints respond (no timeout)
   - [ ] Endpoints return expected data format
   - [ ] Response times reasonable (<10s for search, <30s for complete care)

5. **Fix Backend Timeouts** ‚ö†Ô∏è **IF ENDPOINTS HANG**
   - [ ] Add timeouts to nested HTTP calls (5-10s max per service)
   - [ ] Make endpoints fail fast (return partial results if some services fail)
   - [ ] Add proper error messages (timeout vs error 500 vs network error)

**Acceptance Criteria:**
- ‚úÖ Unified pipeline test passes
- ‚úÖ Matching agent test passes  
- ‚úÖ Backend endpoints respond within timeout limits
- ‚úÖ No hanging/timeout errors

---

### **P1: HIGH - Automation** ‚ö†Ô∏è **DO AFTER P0**

**Status:** ‚ùå **NOT DONE** - Scripts exist but no scheduler

**Tasks:**

1. **Create Refresh Scheduler** üìÖ
   - **File:** `production/core/refresh_scheduler.py` (NEW)
   - **Functionality:**
     - Runs every 24 hours
     - Refreshes top K displayed trials + stale trials (>24h old)
     - Uses `scheduled_refresh_job()` from `refresh_agent.py`
   - **Implementation:**
     ```python
     import asyncio
     import schedule
     import time
     from .refresh_agent import scheduled_refresh_job
     
     def run_refresh_scheduler():
         """Run refresh scheduler (24h interval)."""
         schedule.every(24).hours.do(lambda: asyncio.run(scheduled_refresh_job()))
         
         while True:
             schedule.run_pending()
             time.sleep(3600)  # Check every hour
     ```
   - **Deploy:** Systemd service or cron job
   - [ ] Create `refresh_scheduler.py`
   - [ ] Test scheduler locally
   - [ ] Deploy as systemd service/cron job

2. **Create Auto-Tag Job** üè∑Ô∏è
   - **File:** `production/core/auto_tag_job.py` (NEW)
   - **Functionality:**
     - Runs after new trials are saved (or daily)
     - Tags trials without MoA vectors
     - Uses `run_tagging_pipeline()` from `tagging_agent.py`
   - **Implementation:**
     ```python
     async def auto_tag_new_trials():
         """Auto-tag trials without MoA vectors."""
         # Query SQLite for untagged trials
         # Run tagging pipeline on untagged trials
         # Save to trial_moa_vectors.json
     ```
   - **Trigger:** Hook into `save_trials_to_sqlite()` or scheduled job
   - [ ] Create `auto_tag_job.py`
   - [ ] Test auto-tagging on new trials
   - [ ] Integrate with pipeline or scheduler

3. **Create Auto-Sync Job** üîÑ
   - **File:** `production/core/auto_sync_job.py` (NEW)
   - **Functionality:**
     - Runs after new trials are saved (or daily)
     - Syncs new trials to AstraDB for vector search
     - Uses `sync_trials_to_astradb()` from utilities
   - **Implementation:**
     ```python
     async def auto_sync_new_trials(nct_ids: List[str]):
         """Auto-sync new trials to AstraDB."""
         # Query SQLite for new trials
         # Generate embeddings if needed
         # Upsert to AstraDB
     ```
   - **Trigger:** Hook into `save_trials_to_sqlite()` or scheduled job
   - [ ] Create `auto_sync_job.py`
   - [ ] Test auto-sync on new trials
   - [ ] Integrate with pipeline or scheduler

4. **Create Unified Scheduler** üéØ
   - **File:** `production/run_scheduler.py` (NEW)
   - **Functionality:**
     - Runs all background jobs:
       - Refresh (24h)
       - Tag new trials (daily or on-demand)
       - Sync to AstraDB (daily or on-demand)
   - **Implementation:**
     ```python
     """
     Unified Production Scheduler
     
     Runs all background jobs:
     - Refresh (24h)
     - Tag new trials (on-demand or daily)
     - Sync to AstraDB (on-demand or daily)
     """
     ```
   - [ ] Create `run_scheduler.py`
   - [ ] Integrate all background jobs
   - [ ] Test unified scheduler
   - [ ] Deploy as systemd service/cron job

**Acceptance Criteria:**
- ‚úÖ Refresh scheduler runs every 24h
- ‚úÖ New trials auto-tagged when saved
- ‚úÖ New trials auto-synced to AstraDB
- ‚úÖ Unified scheduler manages all background jobs

---

### **P2: MEDIUM - Increase MoA Coverage** üìä

**Status:** ‚ö†Ô∏è **IN PROGRESS** - 585/1,397 tagged (42%)

**Current Coverage:**
- **Total Trials:** 1,397 in SQLite
- **MoA Tagged:** 585 trials (42%)
- **MoA Untagged:** 812 trials (58%)

**Target Coverage:**
- **Minimum for Production:** 70% of recruiting trials per disease
- **Ideal for Production:** 80%+ of all trials

**Tasks:**

1. **Tag All Recruiting Ovarian Trials** üéØ **PRIORITY**
   - **Why:** Ayesha-specific priority
   - **How:**
     ```bash
     # Find recruiting ovarian trials
     SELECT id FROM trials 
     WHERE conditions LIKE '%ovarian%' 
       AND overall_status = 'RECRUITING'
       AND id NOT IN (SELECT nct_id FROM trial_moa_vectors.json)
     
     # Tag them
     python production/run_tagging.py --nct-ids NCT001,NCT002,... --batch-size 10
     ```
   - [ ] Query SQLite for recruiting ovarian trials without MoA vectors
   - [ ] Run tagging pipeline on these trials
   - [ ] Verify MoA vectors saved to `trial_moa_vectors.json`

2. **Tag Displayed Trials (100% Coverage)** üéØ **CRITICAL**
   - **Why:** Mechanism fit ranking only works for tagged trials
   - **How:**
     - Identify top 100-200 displayed trials per disease
     - Ensure these trials have MoA vectors
     - If displaying top 10, ensure those 10 have MoA vectors
   - [ ] Identify displayed trials (top 100-200 per disease)
   - [ ] Check which ones lack MoA vectors
   - [ ] Tag missing trials
   - [ ] Verify 100% coverage for displayed trials

3. **Batch Tag Remaining Trials** üì¶
   - **Target:** 70%+ overall coverage
   - **Priority Order:**
     1. Recruiting trials (all diseases)
     2. Active trials (all diseases)
     3. Phase III trials (all diseases)
     4. Remaining trials (all statuses)
   - **How:**
     ```bash
     # Tag recruiting trials
     python production/run_tagging.py --limit 200 --batch-size 10
     
     # Tag active trials
     python production/run_tagging.py --limit 200 --batch-size 10
     
     # Continue until 70%+ coverage
     ```
   - [ ] Tag recruiting trials (priority)
   - [ ] Tag active trials
   - [ ] Tag Phase III trials
   - [ ] Verify coverage reaches 70%+

**Acceptance Criteria:**
- ‚úÖ 100% coverage for displayed trials (top 100-200 per disease)
- ‚úÖ 70%+ coverage for recruiting trials per disease
- ‚úÖ 70%+ overall coverage

---

### **P3: ONGOING - Monitoring & Optimization** üìà

**Status:** ‚ö†Ô∏è **ONGOING** - Continuous improvement

**Tasks:**

1. **Monitor CT.gov API Success Rate** üìä
   - **Target:** 95%+ success rate (after fix)
   - **How:**
     - Log all API calls
     - Track success/failure rates
     - Alert on failure rate >5%
   - [ ] Add logging for CT.gov API calls
   - [ ] Track success/failure rates
   - [ ] Set up alerts for high failure rates

2. **Monitor Tagging Pipeline Performance** ‚è±Ô∏è
   - **Target:** <5 min per 100 trials
   - **How:**
     - Log tagging pipeline execution time
     - Track batch processing times
     - Optimize batch size if needed
   - [ ] Add timing logs to tagging pipeline
   - [ ] Track performance metrics
   - [ ] Optimize batch size if needed

3. **Monitor AstraDB Sync Performance** ‚ö°
   - **Target:** <2 min per 100 trials
   - **How:**
     - Log sync execution time
     - Track upsert performance
     - Optimize batch size if needed
   - [ ] Add timing logs to AstraDB sync
   - [ ] Track performance metrics
   - [ ] Optimize batch size if needed

4. **Backend Endpoint Optimization** üöÄ
   - **If endpoints are slow:**
     - Add caching for frequently accessed data
     - Optimize database queries
     - Add connection pooling
     - Implement request queuing
   - [ ] Profile slow endpoints
   - [ ] Add caching where appropriate
   - [ ] Optimize database queries
   - [ ] Add connection pooling

**Acceptance Criteria:**
- ‚úÖ CT.gov API success rate >95%
- ‚úÖ Tagging pipeline <5 min per 100 trials
- ‚úÖ AstraDB sync <2 min per 100 trials
- ‚úÖ Backend endpoints respond <10s

---

## üß™ TESTING GUIDE

### **Test 1: Unified Pipeline** ‚úÖ

**Command:**
```bash
cd oncology-coPilot/oncology-backend-minimal/scripts/trials/production
python run_pipeline.py --disease "ovarian cancer" --count 10 --tag
```

**Expected Output:**
```
üöÄ Starting unified pipeline for ovarian cancer (count=10)
Fetching 10 trials for 'ovarian cancer' from CT.gov...
‚úÖ Fetched 10 trials from CT.gov
‚úÖ Deduped: 8 new trials, 2 duplicates
‚úÖ Saved 8 new trials to SQLite
‚úÖ Tagged 8 trials with MoA vectors
‚úÖ Pipeline complete
```

**Verification:**
```bash
# Check SQLite
sqlite3 oncology-backend-minimal/data/clinical_trials.db \
  "SELECT COUNT(*) FROM trials WHERE id LIKE 'NCT%' AND scraped_at > datetime('now', '-1 hour')"

# Check MoA vectors
cat api/resources/trial_moa_vectors.json | jq 'keys | length'
```

---

### **Test 2: Matching Agent** ‚úÖ

**Command:**
```bash
cd oncology-coPilot/oncology-backend-minimal/scripts/trials/production
python run_matching.py
```

**Expected Output:**
```
‚öîÔ∏è Running Patient Matching + Dossier (Production - Concern D)
‚úÖ Discovery: 250 candidates found
‚úÖ Refresh: 5 trials refreshed
‚úÖ MoA enrichment: 5 trials enriched
‚úÖ Holistic scoring: 5 trials scored
‚úÖ Trials matched: 5

Results:
  NCT04284969: holistic=0.944, status=RECRUITING
  NCT04001023: holistic=0.912, status=RECRUITING
  ...
```

**Verification:**
- ‚úÖ At least 1 query generated (never 0)
- ‚úÖ Candidates discovered (200+ trials)
- ‚úÖ Holistic scores computed (0.0-1.0)
- ‚úÖ Trials matched and returned (5+ trials)
- ‚úÖ Status preserved from discovery (not UNKNOWN)

---

### **Test 3: Backend Endpoints** ‚úÖ

**Commands:**
```bash
# Test health
curl http://localhost:8000/api/health

# Test trials search
curl -X POST http://localhost:8000/api/trials/agent/search \
  -H "Content-Type: application/json" \
  -d '{"query":"ovarian cancer","disease":"ovarian_cancer_hgs"}' \
  --max-time 30

# Test complete care
curl -X POST http://localhost:8000/api/complete_care/v2 \
  -H "Content-Type: application/json" \
  -d '{"patient_profile":{"disease":"ovarian_cancer_hgs","stage":"IVB"}}' \
  --max-time 30
```

**Expected Output:**
- ‚úÖ Health endpoint: `{"status": "healthy"}`
- ‚úÖ Trials search: Returns JSON with trials array
- ‚úÖ Complete care: Returns JSON with complete care plan
- ‚úÖ Response times: <10s for search, <30s for complete care

**If Endpoints Fail:**
1. Check backend logs: `tail -f backend.log | grep -i error`
2. Verify backend is running: `ps aux | grep uvicorn`
3. Test imports: `python3 -c "from api.main import app"`
4. Check database connections (Supabase/AstraDB/SQLite)

---

## üìä CURRENT METRICS

### **Database Status**
- **Total Trials:** 1,397 in SQLite
- **MoA Tagged:** 585 trials (42%)
- **MoA Untagged:** 812 trials (58%)
- **Database Path:** `oncology-backend-minimal/data/clinical_trials.db`

### **MoA Coverage by Status**
- **Recruiting:** TBD (needs query)
- **Active:** TBD (needs query)
- **Completed:** TBD (needs query)

### **Pipeline Performance**
- **CT.gov API:** ‚úÖ Fixed (validation, batching, URL length)
- **Tagging Pipeline:** TBD (needs monitoring)
- **AstraDB Sync:** TBD (needs monitoring)

### **Backend Status**
- **Health Endpoint:** ‚ö†Ô∏è **UNTESTED**
- **Trials Search:** ‚ö†Ô∏è **UNTESTED**
- **Complete Care:** ‚ö†Ô∏è **UNTESTED**

---

## üéØ SUCCESS CRITERIA

### **For P0 (Testing)**
- ‚úÖ Unified pipeline test passes
- ‚úÖ Matching agent test passes
- ‚úÖ Backend endpoints respond within timeout limits
- ‚úÖ No hanging/timeout errors

### **For P1 (Automation)**
- ‚úÖ Refresh scheduler runs every 24h
- ‚úÖ New trials auto-tagged when saved
- ‚úÖ New trials auto-synced to AstraDB
- ‚úÖ Unified scheduler manages all background jobs

### **For P2 (MoA Coverage)**
- ‚úÖ 100% coverage for displayed trials (top 100-200 per disease)
- ‚úÖ 70%+ coverage for recruiting trials per disease
- ‚úÖ 70%+ overall coverage

### **For P3 (Monitoring)**
- ‚úÖ CT.gov API success rate >95%
- ‚úÖ Tagging pipeline <5 min per 100 trials
- ‚úÖ AstraDB sync <2 min per 100 trials
- ‚úÖ Backend endpoints respond <10s

---

## üìù NOTES & GOTCHAS

### **Profile Format Support**
- ‚úÖ Supports both nested and flat formats
- ‚úÖ Helper function: `_extract_profile_field()` handles both
- ‚úÖ Multiple field paths checked: `['disease.primary_diagnosis', 'disease', 'primary_diagnosis']`

### **Discovery Data Preservation**
- ‚úÖ Discovery returns full trial objects with status
- ‚úÖ These are preserved even if refresh fails
- ‚úÖ Priority: Refresh ‚Üí Discovery ‚Üí UNKNOWN (last resort)

### **Query Generation Fallback**
- ‚úÖ Always produces at least one query (fallback: "cancer clinical trial")
- ‚úÖ Autonomous agent fallback checks for empty queries
- ‚úÖ Manual query generation always succeeds

### **CT.gov API Limitations**
- ‚úÖ Max 100 NCT IDs per request
- ‚úÖ URL length limit ~5000 chars
- ‚úÖ Invalid NCT IDs are filtered out
- ‚úÖ Detailed error logging for 400 errors

---

## üöÄ QUICK START

### **For Testing (P0)**
```bash
# 1. Test unified pipeline
cd oncology-coPilot/oncology-backend-minimal/scripts/trials/production
python run_pipeline.py --disease "ovarian cancer" --count 10 --tag

# 2. Test matching agent
python run_matching.py

# 3. Test backend endpoints
curl http://localhost:8000/api/health
curl -X POST http://localhost:8000/api/trials/agent/search \
  -H "Content-Type: application/json" \
  -d '{"query":"ovarian cancer"}' --max-time 30
```

### **For Automation (P1)**
```bash
# 1. Create refresh scheduler
# Edit: production/core/refresh_scheduler.py

# 2. Create auto-tag job
# Edit: production/core/auto_tag_job.py

# 3. Create auto-sync job
# Edit: production/core/auto_sync_job.py

# 4. Create unified scheduler
# Edit: production/run_scheduler.py
```

### **For MoA Coverage (P2)**
```bash
# 1. Tag recruiting ovarian trials
python production/run_tagging.py --nct-ids NCT001,NCT002,... --batch-size 10

# 2. Tag displayed trials
# Query SQLite for top 100-200 trials per disease
# Run tagging pipeline on missing trials

# 3. Batch tag remaining trials
python production/run_tagging.py --limit 200 --batch-size 10
```

---

## üìû SUPPORT & QUESTIONS

### **If You Get Stuck**
1. Check this document first (HANDOFF_MASTER.md)
2. Check individual agent documentation:
   - `production/STATUS.md` - Current status
   - `PRODUCTION_STRUCTURE.md` - Architecture overview
   - Agent-specific docs in `production/core/`
3. Review error logs:
   - Backend logs: `tail -f backend.log`
   - Python logs: Check console output
   - Database logs: SQLite errors in console

### **Key Files to Know**
- **Entry Points:** `production/run_*.py`
- **Core Logic:** `production/core/*_agent.py`
- **Unified Pipeline:** `production/run_pipeline.py`
- **MoA Vectors:** `api/resources/trial_moa_vectors.json`
- **Database:** `oncology-backend-minimal/data/clinical_trials.db`
- **AstraDB Sync:** `utilities/seed_astradb_from_sqlite.py` (‚úÖ Vector storage fixed - see `utilities/VECTOR_STORAGE_FIX_COMPLETE.md`)

---

## ‚úÖ HANDOFF CHECKLIST

**For JR3/Alpha (Executor):**
- [ ] Read this document (HANDOFF_MASTER.md)
- [ ] Understand directory structure
- [ ] Review completed work
- [ ] Start with P0 (Testing) - **DO FIRST**
- [ ] Move to P1 (Automation) after P0 passes
- [ ] Work on P2 (MoA Coverage) in parallel
- [ ] Set up P3 (Monitoring) for ongoing work

**For Zo (Overseer):**
- [x] Consolidate all documentation
- [x] Create handoff document
- [x] Outline all remaining work
- [x] Provide clear priority order
- [ ] Review P0 test results
- [ ] Review P1 automation work
- [ ] Review P2 MoA coverage progress
- [ ] Monitor P3 performance metrics

---

**Status:** ‚úÖ **HANDOFF DOCUMENT COMPLETE**  
**Next Step:** Start with P0 (Testing) - **CRITICAL**

**‚öîÔ∏è READY TO SUPPORT CANCER PATIENTS! üöÄ**
