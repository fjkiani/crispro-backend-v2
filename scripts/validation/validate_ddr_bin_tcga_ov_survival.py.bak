#!/usr/bin/env python3
"""
DDR_bin Retrospective Validation (TCGA-OV Survival Analysis)

Validates DDR_bin association with PFS/OS in TCGA-OV cohort.
Links Tier-3 SAE cohort (149 patients) to cBioPortal survival data.

Exit codes:
  0: Minimum "signal present" gate passed
  2: Not enough linked/usable patients (data issue)
  3: Ran but gates failed (no signal)
"""

import json
import math
import sys
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from collections import defaultdict

import numpy as np
import scipy.stats
import matplotlib
matplotlib.use('Agg')  # Non-interactive backend
import matplotlib.pyplot as plt

# Paths (relative to repo root)
REPO_ROOT = Path(__file__).parent.parent.parent.parent.parent
CBIOPORTAL_DATASET = REPO_ROOT / "data" / "benchmarks" / "cbioportal_trial_datasets_latest.json"
TIER3_COHORT = REPO_ROOT / "oncology-coPilot" / "oncology-backend-minimal" / "data" / "validation" / "sae_cohort" / "checkpoints" / "Tier3_validation_cohort.json"
DIAMOND_MAPPING = REPO_ROOT / "oncology-coPilot" / "oncology-backend-minimal" / "api" / "resources" / "sae_feature_mapping.true_sae_diamonds.v1.json"
OUTPUT_DIR = REPO_ROOT / "oncology-coPilot" / "oncology-backend-minimal" / "scripts" / "validation" / "out" / "ddr_bin_tcga_ov"

# DDR gene set (frozen for reproducibility)
DDR_GENES = {
    "BRCA1", "BRCA2", "ATM", "ATR", "CHEK2", "RAD51C", "RAD51D",
    "PALB2", "BARD1", "BRIP1", "FANCA", "FANCD2", "NBN", "MRE11A",
    "TP53", "MBD4"
}


def parse_event_status(status_str: Optional[str]) -> Optional[int]:
    """Parse event status from cBioPortal format.
    
    Returns:
        1 if event occurred (status starts with "1:"), 0 if censored, None if missing/invalid
    """
    if not status_str or not isinstance(status_str, str):
        return None
    if status_str.startswith("1:"):
        return 1
    if status_str.startswith("0:"):
        return 0
    return None


def parse_months(value) -> Optional[float]:
    """Parse months field, handling NaN strings and None."""
    if value is None:
        return None
    if isinstance(value, str):
        if value.lower() in ("nan", "none", ""):
            return None
        try:
            return float(value)
        except ValueError:
            return None
    try:
        fval = float(value)
        if math.isnan(fval):
            return None
        return fval
    except (ValueError, TypeError):
        return None


def load_diamond_features() -> List[int]:
    """Load diamond feature indices from mapping file."""
    if not DIAMOND_MAPPING.exists():
        raise FileNotFoundError(f"Diamond mapping not found: {DIAMOND_MAPPING}")
    
    with open(DIAMOND_MAPPING) as f:
        mapping = json.load(f)
    
    features = mapping.get("features", [])
    if not features:
        raise ValueError("No features found in diamond mapping")
    
    diamond_indices = []
    for feat in features:
        idx = feat.get("feature_index")
        if idx is not None:
            diamond_indices.append(int(idx))
    
    if not diamond_indices:
        raise ValueError("No valid feature indices found")
    
    print(f"Loaded {len(diamond_indices)} diamond features")
    return sorted(diamond_indices)


def compute_ddr_bin(patient_data: Dict, diamond_indices: List[int]) -> Dict:
    """Compute DDR_bin score for a patient from Tier-3 variant data.
    
    Returns:
        {
            "ddr_bin": float,
            "ddr_bin_variant_max_values": List[float],
            "ddr_bin_num_variants": int,
            "ddr_bin_coverage": float
        }
    """
    variants = patient_data.get("variants", [])
    if not variants:
        return {
            "ddr_bin": 0.0,
            "ddr_bin_variant_max_values": [],
            "ddr_bin_num_variants": 0,
            "ddr_bin_coverage": 0.0
        }
    
    variant_ddr_scores = []
    variants_with_diamond = 0
    
    for variant in variants:
        top_features = variant.get("top_features", [])
        if not top_features:
            continue
        
        # Build feature value map: {index: value}
        feature_map = {}
        for tf in top_features:
            idx = tf.get("index")
            val = tf.get("value", 0.0)
            if idx is not None and val is not None:
                try:
                    feature_map[int(idx)] = float(val)
                except (ValueError, TypeError):
                    pass
        
        # Compute variant-level DDR score (max of diamond features)
        variant_ddr = 0.0
        has_diamond = False
        for diamond_idx in diamond_indices:
            if diamond_idx in feature_map:
                variant_ddr = max(variant_ddr, abs(feature_map[diamond_idx]))
                has_diamond = True
        
        if has_diamond:
            variants_with_diamond += 1
        
        variant_ddr_scores.append(variant_ddr)
    
    # Patient DDR_bin = max across all variants
    ddr_bin = max(variant_ddr_scores) if variant_ddr_scores else 0.0
    
    coverage = variants_with_diamond / len(variants) if variants else 0.0
    
    return {
        "ddr_bin": float(ddr_bin),
        "ddr_bin_variant_max_values": variant_ddr_scores,
        "ddr_bin_num_variants": len(variants),
        "ddr_bin_coverage": float(coverage)
    }


def compute_gene_ddr(mutations: List[Dict]) -> int:
    """Compute binary gene-level DDR flag."""
    if not mutations:
        return 0
    
    genes = set()
    for mut in mutations:
        if isinstance(mut, dict):
            gene = mut.get("gene")
            if gene:
                genes.add(str(gene).upper())
        elif isinstance(mut, str):
            genes.add(mut.upper())
    
    return 1 if bool(genes & DDR_GENES) else 0


def link_patients() -> List[Dict]:
    """Link Tier-3 patients to cBioPortal survival data."""
    # Load Tier-3 cohort
    if not TIER3_COHORT.exists():
        raise FileNotFoundError(f"Tier-3 cohort not found: {TIER3_COHORT}")
    
    with open(TIER3_COHORT) as f:
        tier3_data = json.load(f)
    
    tier3_patients = tier3_data.get("data", {})
    print(f"Loaded {len(tier3_patients)} Tier-3 patients")
    
    # Load cBioPortal dataset
    if not CBIOPORTAL_DATASET.exists():
        raise FileNotFoundError(f"cBioPortal dataset not found: {CBIOPORTAL_DATASET}")
    
    with open(CBIOPORTAL_DATASET) as f:
        cbioportal_data = json.load(f)
    
    # Find ov_tcga study
    ov_study = None
    for study in cbioportal_data:
        if study.get("study_id") == "ov_tcga":
            ov_study = study
            break
    
    if not ov_study:
        raise ValueError("ov_tcga study not found in cBioPortal dataset")
    
    cbioportal_patients = {p.get("patient_id"): p for p in ov_study.get("patients", [])}
    print(f"Loaded {len(cbioportal_patients)} cBioPortal patients")
    
    # Link by patient_id
    linked = []
    diamond_indices = load_diamond_features()
    
    for patient_id, tier3_info in tier3_patients.items():
        cbioportal_info = cbioportal_patients.get(patient_id)
        if not cbioportal_info:
            continue
        
        # Compute DDR_bin
        ddr_bin_info = compute_ddr_bin(tier3_info, diamond_indices)
        
        # Extract survival data
        outcomes = cbioportal_info.get("clinical_outcomes", {})
        
        pfs_months = parse_months(outcomes.get("PFS_MONTHS"))
        pfs_event = parse_event_status(outcomes.get("PFS_STATUS"))
        os_months = parse_months(outcomes.get("OS_MONTHS"))
        os_event = parse_event_status(outcomes.get("OS_STATUS"))
        
        # Extract mutations for gene-level DDR
        mutations = cbioportal_info.get("mutations", [])
        gene_ddr = compute_gene_ddr(mutations)
        
        # Extract confounders
        stage = outcomes.get("CLINICAL_STAGE")
        age = parse_months(outcomes.get("AGE"))  # Reuse parse_months for numeric fields
        residual = outcomes.get("RESIDUAL_TUMOR")
        
        linked.append({
            "patient_id": patient_id,
            "ddr_bin": ddr_bin_info["ddr_bin"],
            "ddr_bin_coverage": ddr_bin_info["ddr_bin_coverage"],
            "ddr_bin_num_variants": ddr_bin_info["ddr_bin_num_variants"],
            "pfs_months": pfs_months,
            "pfs_event": pfs_event,
            "os_months": os_months,
            "os_event": os_event,
            "gene_ddr": gene_ddr,
            "stage": stage,
            "age": age,
            "residual_tumor": residual
        })
    
    print(f"Linked {len(linked)} patients")
    return linked


def compute_c_index(time: np.ndarray, event: np.ndarray, score: np.ndarray) -> float:
    """Compute Harrell's C-index (concordance index).
    
    Higher score should predict shorter survival (for resistance markers).
    """
    if len(time) < 2:
        return 0.5
    
    # Sort by time
    order = np.argsort(time)
    time_sorted = time[order]
    event_sorted = event[order]
    score_sorted = score[order]
    
    concordant = 0
    discordant = 0
    tied_time = 0
    tied_score = 0
    
    for i in range(len(time_sorted)):
        if event_sorted[i] == 0:  # Censored, skip
            continue
        
        for j in range(i + 1, len(time_sorted)):
            if time_sorted[j] <= time_sorted[i]:  # j died/censored before i's event
                continue
            
            # Compare scores (higher score = worse outcome)
            if score_sorted[i] > score_sorted[j]:
                concordant += 1
            elif score_sorted[i] < score_sorted[j]:
                discordant += 1
            else:
                tied_score += 1
    
    total = concordant + discordant + tied_score
    if total == 0:
        return 0.5
    
    return concordant / total if total > 0 else 0.5


def logrank_test(time: np.ndarray, event: np.ndarray, group: np.ndarray) -> float:
    """Manual log-rank test (simplified).
    
    Returns p-value.
    """
    if len(np.unique(group)) < 2:
        return 1.0
    
    # Simplified: use Mann-Whitney U on event times (weighted by events)
    group0_mask = group == 0
    group1_mask = group == 1
    
    time0 = time[group0_mask]
    event0 = event[group0_mask]
    time1 = time[group1_mask]
    event1 = event[group1_mask]
    
    # Weight by event status
    weighted_time0 = time0 * event0
    weighted_time1 = time1 * event1
    
    # Mann-Whitney U test
    try:
        u_stat, p_value = scipy.stats.mannwhitneyu(
            weighted_time0, weighted_time1, alternative='two-sided'
        )
        return float(p_value)
    except Exception:
        return 1.0


def analyze_survival(linked: List[Dict], endpoint: str) -> Dict:
    """Analyze survival endpoint (PFS or OS)."""
    months_key = f"{endpoint}_months"
    event_key = f"{endpoint}_event"
    
    # Filter usable patients
    usable = [
        p for p in linked
        if p[months_key] is not None and p[event_key] is not None
    ]
    
    if len(usable) < 10:
        return {
            "usable": len(usable),
            "pearson_r": 0.0,
            "pearson_p": 1.0,
            "spearman_rho": 0.0,
            "spearman_p": 1.0,
            "logrank_p": 1.0,
            "median_months_high": None,
            "median_months_low": None,
            "c_index_ddr_bin": None
        }
    
    ddr_bin = np.array([p["ddr_bin"] for p in usable])
    time = np.array([p[months_key] for p in usable])
    event = np.array([p[event_key] for p in usable])
    
    # Correlations
    pearson_r, pearson_p = scipy.stats.pearsonr(ddr_bin, time)
    spearman_rho, spearman_p = scipy.stats.spearmanr(ddr_bin, time)
    
    # Median split
    median_ddr = np.median(ddr_bin)
    group = (ddr_bin > median_ddr).astype(int)
    
    # Log-rank test
    logrank_p = logrank_test(time, event, group)
    
    # Median survival by group
    group0_time = time[group == 0]
    group0_event = event[group == 0]
    group1_time = time[group == 1]
    group1_event = event[group == 1]
    
    # Simple median (ignoring censoring for simplicity)
    median_low = np.median(group0_time) if len(group0_time) > 0 else None
    median_high = np.median(group1_time) if len(group1_time) > 0 else None
    
    # C-index
    c_index = compute_c_index(time, event, ddr_bin)
    
    return {
        "usable": len(usable),
        "pearson_r": float(pearson_r),
        "pearson_p": float(pearson_p),
        "spearman_rho": float(spearman_rho),
        "spearman_p": float(spearman_p),
        "logrank_p": float(logrank_p),
        "median_months_high": float(median_high) if median_high is not None else None,
        "median_months_low": float(median_low) if median_low is not None else None,
        "c_index_ddr_bin": float(c_index)
    }


def plot_km_curves(linked: List[Dict], endpoint: str, output_path: Path):
    """Plot Kaplan-Meier curves (simplified, manual implementation)."""
    months_key = f"{endpoint}_months"
    event_key = f"{endpoint}_event"
    
    usable = [
        p for p in linked
        if p[months_key] is not None and p[event_key] is not None
    ]
    
    if len(usable) < 10:
        return
    
    ddr_bin = np.array([p["ddr_bin"] for p in usable])
    time = np.array([p[months_key] for p in usable])
    event = np.array([p[event_key] for p in usable])
    
    median_ddr = np.median(ddr_bin)
    group = (ddr_bin > median_ddr).astype(int)
    
    # Simple KM curves (step function)
    fig, ax = plt.subplots(figsize=(10, 6))
    
    for g, label in [(0, "DDR_bin Low"), (1, "DDR_bin High")]:
        mask = group == g
        if not np.any(mask):
            continue
        
        t = time[mask]
        e = event[mask]
        
        # Sort by time
        order = np.argsort(t)
        t_sorted = t[order]
        e_sorted = e[order]
        
        # Compute survival curve
        n = len(t_sorted)
        surv = np.ones(n + 1)
        time_points = np.concatenate([[0], t_sorted])
        
        for i in range(n):
            if e_sorted[i] == 1:
                surv[i + 1] = surv[i] * (1 - 1 / (n - i))
            else:
                surv[i + 1] = surv[i]
        
        ax.step(time_points, surv, where='post', label=label, linewidth=2)
    
    ax.set_xlabel(f"{endpoint.upper()} Time (months)")
    ax.set_ylabel("Survival Probability")
    ax.set_title(f"Kaplan-Meier Curves: {endpoint.upper()} by DDR_bin")
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=150)
    plt.close()


def plot_ddr_bin_distribution(linked: List[Dict], output_path: Path):
    """Plot DDR_bin distribution histogram."""
    ddr_bin_values = [p["ddr_bin"] for p in linked if p["ddr_bin"] is not None]
    
    if not ddr_bin_values:
        return
    
    fig, ax = plt.subplots(figsize=(8, 6))
    ax.hist(ddr_bin_values, bins=30, edgecolor='black', alpha=0.7)
    ax.set_xlabel("DDR_bin Score")
    ax.set_ylabel("Frequency")
    ax.set_title("DDR_bin Distribution (Tier-3 Cohort)")
    ax.axvline(np.median(ddr_bin_values), color='red', linestyle='--', label=f'Median: {np.median(ddr_bin_values):.3f}')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=150)
    plt.close()


def main():
    """Main validation workflow."""
    print("=" * 80)
    print("DDR_bin Retrospective Validation (TCGA-OV)")
    print("=" * 80)
    
    # Create output directory
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    # Link patients
    print("\n[1/4] Linking Tier-3 patients to cBioPortal survival data...")
    try:
        linked = link_patients()
    except Exception as e:
        print(f"ERROR: Failed to link patients: {e}")
        sys.exit(2)
    
    if len(linked) < 10:
        print(f"ERROR: Only {len(linked)} linked patients (need ≥10)")
        sys.exit(2)
    
    # Compute DDR_bin summary
    ddr_bin_values = [p["ddr_bin"] for p in linked]
    ddr_bin_summary = {
        "min": float(np.min(ddr_bin_values)),
        "median": float(np.median(ddr_bin_values)),
        "max": float(np.max(ddr_bin_values))
    }
    
    # Analyze PFS
    print("\n[2/4] Analyzing PFS...")
    pfs_results = analyze_survival(linked, "pfs")
    
    # Analyze OS
    print("\n[3/4] Analyzing OS...")
    os_results = analyze_survival(linked, "os")
    
    # Head-to-head comparison (gene-level DDR vs DDR_bin)
    print("\n[4/4] Head-to-head comparison...")
    pfs_usable = [
        p for p in linked
        if p["pfs_months"] is not None and p["pfs_event"] is not None
    ]
    
    head_to_head = {}
    if len(pfs_usable) >= 10:
        time = np.array([p["pfs_months"] for p in pfs_usable])
        event = np.array([p["pfs_event"] for p in pfs_usable])
        ddr_bin = np.array([p["ddr_bin"] for p in pfs_usable])
        gene_ddr = np.array([p["gene_ddr"] for p in pfs_usable])
        
        c_index_ddr_bin = compute_c_index(time, event, ddr_bin)
        c_index_gene_ddr = compute_c_index(time, event, gene_ddr.astype(float))
        
        head_to_head = {
            "c_index_ddr_bin_pfs": float(c_index_ddr_bin),
            "c_index_gene_ddr_pfs": float(c_index_gene_ddr),
            "delta_c_index": float(c_index_ddr_bin - c_index_gene_ddr)
        }
    else:
        head_to_head = {
            "c_index_ddr_bin_pfs": None,
            "c_index_gene_ddr_pfs": None,
            "delta_c_index": None
        }
    
    # Generate plots
    print("\nGenerating plots...")
    plot_km_curves(linked, "pfs", OUTPUT_DIR / "km_pfs.png")
    plot_km_curves(linked, "os", OUTPUT_DIR / "km_os.png")
    plot_ddr_bin_distribution(linked, OUTPUT_DIR / "ddr_bin_hist.png")
    
    # Export linked patients CSV
    import csv
    with open(OUTPUT_DIR / "linked_patients.csv", "w", newline="") as f:
        # Only include fields that exist in all linked records
        fieldnames = [
            "patient_id", "ddr_bin", "ddr_bin_coverage", "ddr_bin_num_variants",
            "pfs_months", "pfs_event", "os_months", "os_event",
            "gene_ddr", "stage", "age", "residual_tumor"
        ]
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(linked)
    
    # Build report
    report = {
        "run_meta": {
            "study_id": "ov_tcga",
            "tier3_patients_total": len(linked),
            "linked_patients": len(linked),
            "pfs_usable": pfs_results["usable"],
            "os_usable": os_results["usable"],
            "diamond_mapping_version": "v1",
            "data_files": {
                "cbioportal_dataset": str(CBIOPORTAL_DATASET.relative_to(REPO_ROOT)),
                "tier3": str(TIER3_COHORT.relative_to(REPO_ROOT)),
                "diamonds": str(DIAMOND_MAPPING.relative_to(REPO_ROOT))
            }
        },
        "ddr_bin_summary": ddr_bin_summary,
        "pfs": pfs_results,
        "os": os_results,
        "head_to_head": head_to_head,
        "verdict": {
            "status": "pending",
            "reasons": []
        }
    }
    
    # Determine verdict
    verdict_reasons = []
    
    # Minimum gate: log-rank p < 0.10 OR |Spearman| ≥ 0.15
    pfs_passed = (pfs_results["logrank_p"] < 0.10) or (abs(pfs_results["spearman_rho"]) >= 0.15)
    os_passed = (os_results["logrank_p"] < 0.10) or (abs(os_results["spearman_rho"]) >= 0.15)
    
    if pfs_passed or os_passed:
        report["verdict"]["status"] = "pass"
        if pfs_passed:
            verdict_reasons.append(f"PFS: log-rank p={pfs_results['logrank_p']:.4f} OR |Spearman|={abs(pfs_results['spearman_rho']):.3f}")
        if os_passed:
            verdict_reasons.append(f"OS: log-rank p={os_results['logrank_p']:.4f} OR |Spearman|={abs(os_results['spearman_rho']):.3f}")
    else:
        report["verdict"]["status"] = "fail"
        verdict_reasons.append("Neither PFS nor OS met minimum gate (log-rank p < 0.10 OR |Spearman| ≥ 0.15)")
    
    report["verdict"]["reasons"] = verdict_reasons
    
    # Save report
    with open(OUTPUT_DIR / "report.json", "w") as f:
        json.dump(report, f, indent=2)
    
    # Print summary
    print("\n" + "=" * 80)
    print("VALIDATION SUMMARY")
    print("=" * 80)
    print(f"Linked patients: {len(linked)}")
    print(f"PFS usable: {pfs_results['usable']}")
    print(f"OS usable: {os_results['usable']}")
    print(f"\nPFS:")
    print(f"  Spearman ρ: {pfs_results['spearman_rho']:.3f} (p={pfs_results['spearman_p']:.4f})")
    print(f"  Log-rank p: {pfs_results['logrank_p']:.4f}")
    print(f"  C-index: {pfs_results['c_index_ddr_bin']:.3f}" if pfs_results['c_index_ddr_bin'] else "  C-index: N/A")
    print(f"\nOS:")
    print(f"  Spearman ρ: {os_results['spearman_rho']:.3f} (p={os_results['spearman_p']:.4f})")
    print(f"  Log-rank p: {os_results['logrank_p']:.4f}")
    print(f"  C-index: {os_results['c_index_ddr_bin']:.3f}" if os_results['c_index_ddr_bin'] else "  C-index: N/A")
    if head_to_head.get("delta_c_index") is not None:
        print(f"\nHead-to-head:")
        print(f"  DDR_bin C-index: {head_to_head['c_index_ddr_bin_pfs']:.3f}")
        print(f"  Gene-level DDR C-index: {head_to_head['c_index_gene_ddr_pfs']:.3f}")
        print(f"  Delta: {head_to_head['delta_c_index']:.3f}")
    print(f"\nVerdict: {report['verdict']['status'].upper()}")
    for reason in verdict_reasons:
        print(f"  - {reason}")
    print(f"\nOutputs saved to: {OUTPUT_DIR}")
    print("=" * 80)
    
    # Exit code
    if report["verdict"]["status"] == "pass":
        sys.exit(0)
    else:
        sys.exit(3)


if __name__ == "__main__":
    main()
