"""
Ayesha Dossiers API Router
Serves trial intelligence dossiers for frontend display.

This router serves the markdown dossiers generated by the modular pipeline,
located in .cursor/ayesha/zo_fresh_dossiers/
"""
from fastapi import APIRouter, HTTPException, Query
from fastapi.responses import FileResponse, Response
from pathlib import Path
from typing import List, Dict, Any, Optional
import json
import re
import logging

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/ayesha/dossiers", tags=["Ayesha Dossiers"])

# Dossier directory - points to generated intelligence reports
DOSSIER_DIR = Path(__file__).resolve().parent.parent.parent.parent.parent / ".cursor" / "ayesha" / "zo_fresh_dossiers"


def _load_dossiers(
    tier: Optional[str] = None,
    min_score: Optional[float] = None
) -> List[Dict[str, Any]]:
    """
    Helper function to load and parse all dossiers from the directory.
    Returns a list of dossier metadata dictionaries.
    """
    if not DOSSIER_DIR.exists():
        return []
    
    dossiers = []
    
    for file_path in DOSSIER_DIR.glob("INTELLIGENCE_NCT*.md"):
        try:
            content = file_path.read_text(encoding='utf-8')
            
            # Extract metadata from markdown
            nct_id_match = re.search(r'NCT\d+', file_path.name)
            nct_id = nct_id_match.group(0) if nct_id_match else "Unknown"
            
            tier_match = re.search(r'_(TOP_TIER|GOOD_TIER|ACCEPTABLE_TIER)', file_path.name)
            dossier_tier = tier_match.group(1) if tier_match else "UNKNOWN"
            
            score_match = re.search(r'\*\*Composite Score\*\*: ([\d.]+)', content)
            match_score = float(score_match.group(1)) if score_match else 0.0
            
            title_match = re.search(r'\*\*Trial Name\*\*: (.+)', content)
            title = title_match.group(1).strip() if title_match else "Unknown Trial"
            if len(title) > 100:
                title = title[:100] + "..."
            
            phase_match = re.search(r'\*\*Phase\*\*: (.+)', content)
            phase = phase_match.group(1).strip() if phase_match else "N/A"
            
            # Check for LLM analysis (not fallback)
            has_llm = (
                "WHY THIS TRIAL IS A GOOD FIT" in content and
                "Error calling Google Gemini API" not in content
            )
            
            # Apply filters
            if tier and dossier_tier != tier:
                continue
            
            if min_score is not None and match_score < min_score:
                continue
            
            dossiers.append({
                "nct_id": nct_id,
                "tier": dossier_tier,
                "match_score": match_score,
                "title": title,
                "phase": phase,
                "has_llm_analysis": has_llm,
                "file_name": file_path.name
            })
            
        except Exception as e:
            logger.warning(f"Failed to parse dossier {file_path.name}: {e}")
            continue
    
    # Sort by match score descending
    dossiers.sort(key=lambda x: x['match_score'], reverse=True)
    
    return dossiers


@router.get("/health")
async def health_check() -> Dict[str, Any]:
    """Health check for dossier service."""
    return {
        "status": "ok",
        "dossier_dir": str(DOSSIER_DIR),
        "dir_exists": DOSSIER_DIR.exists(),
        "dossier_count": len(list(DOSSIER_DIR.glob("INTELLIGENCE_NCT*.md"))) if DOSSIER_DIR.exists() else 0
    }


@router.get("/list")
async def list_dossiers(
    tier: Optional[str] = Query(None, description="Filter by tier: TOP_TIER, GOOD_TIER, or all"),
    min_score: Optional[float] = Query(None, description="Minimum match score (0.0-1.0)"),
    limit: Optional[int] = Query(None, description="Limit number of results")
) -> Dict[str, Any]:
    """
    List all available dossiers with metadata.
    
    Returns:
        {
            "total": 60,
            "filtered": 10,
            "dossiers": [
                {
                    "nct_id": "NCT06619236",
                    "tier": "TOP_TIER",
                    "match_score": 0.97,
                    "title": "Trial Title...",
                    "phase": "Phase II",
                    "has_llm_analysis": true,
                    "file_name": "INTELLIGENCE_NCT06619236_TOP_TIER.md"
                },
                ...
            ]
        }
    """
    if not DOSSIER_DIR.exists():
        raise HTTPException(
            status_code=404,
            detail=f"Dossier directory not found: {DOSSIER_DIR}"
        )
    
    # Use helper function to load dossiers
    all_dossiers = _load_dossiers(tier=tier, min_score=min_score)
    
    # Apply limit
    total_count = len(all_dossiers)
    if limit and limit > 0:
        all_dossiers = all_dossiers[:limit]
    
    return {
        "total": total_count,
        "filtered": len(all_dossiers),
        "dossiers": all_dossiers
    }


@router.get("/detail/{nct_id}")
async def get_dossier_detail(nct_id: str) -> Dict[str, Any]:
    """
    Get full dossier content for a specific trial.
    
    Args:
        nct_id: NCT identifier (e.g., "NCT06619236")
    
    Returns:
        {
            "nct_id": "NCT06619236",
            "markdown": "Full markdown content...",
            "metadata": {
                "tier": "TOP_TIER",
                "match_score": 0.97,
                "generated_at": "2025-11-15T...",
                "file_name": "INTELLIGENCE_NCT06619236_TOP_TIER.md"
            }
        }
    """
    if not DOSSIER_DIR.exists():
        raise HTTPException(
            status_code=404,
            detail=f"Dossier directory not found: {DOSSIER_DIR}"
        )
    
    # Find matching file
    matching_files = list(DOSSIER_DIR.glob(f"INTELLIGENCE_{nct_id}_*.md"))
    
    if not matching_files:
        raise HTTPException(
            status_code=404,
            detail=f"Dossier for {nct_id} not found in {DOSSIER_DIR}"
        )
    
    file_path = matching_files[0]
    
    try:
        content = file_path.read_text(encoding='utf-8')
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Failed to read dossier file: {e}"
        )
    
    # Extract metadata
    tier_match = re.search(r'_(TOP_TIER|GOOD_TIER|ACCEPTABLE_TIER)', file_path.name)
    tier = tier_match.group(1) if tier_match else "UNKNOWN"
    
    score_match = re.search(r'\*\*Composite Score\*\*: ([\d.]+)', content)
    match_score = float(score_match.group(1)) if score_match else 0.0
    
    generated_match = re.search(r'\*\*Generated\*\*: (.+)', content)
    generated_at = generated_match.group(1).strip() if generated_match else "Unknown"
    
    return {
        "nct_id": nct_id,
        "markdown": content,
        "metadata": {
            "tier": tier,
            "match_score": match_score,
            "generated_at": generated_at,
            "file_name": file_path.name
        }
    }


@router.get("/export/{nct_id}")
async def export_dossier(
    nct_id: str,
    format: str = Query("markdown", description="Export format: markdown, raw")
) -> Response:
    """
    Export dossier in various formats.
    
    Args:
        nct_id: NCT identifier
        format: "markdown" | "raw" (future: "html", "pdf")
    
    Returns:
        File download response
    """
    detail = await get_dossier_detail(nct_id)
    
    if format == "markdown" or format == "raw":
        return Response(
            content=detail["markdown"],
            media_type="text/markdown",
            headers={
                "Content-Disposition": f'attachment; filename="{nct_id}_DOSSIER.md"'
            }
        )
    else:
        raise HTTPException(
            status_code=400,
            detail=f"Unsupported format: {format}. Supported: markdown, raw"
        )


@router.get("/stats")
async def get_dossier_stats() -> Dict[str, Any]:
    """
    Get statistics about available dossiers.
    
    Returns:
        {
            "total": 60,
            "by_tier": {
                "TOP_TIER": 10,
                "GOOD_TIER": 50
            },
            "with_llm": 9,
            "avg_score": 0.85
        }
    """
    if not DOSSIER_DIR.exists():
        return {
            "total": 0,
            "by_tier": {},
            "with_llm": 0,
            "avg_score": 0.0
        }
    
    # Use helper function to load all dossiers (no filters)
    dossiers = _load_dossiers()
    
    by_tier = {}
    with_llm = 0
    total_score = 0.0
    
    for dossier in dossiers:
        tier = dossier["tier"]
        by_tier[tier] = by_tier.get(tier, 0) + 1
        
        if dossier["has_llm_analysis"]:
            with_llm += 1
        
        total_score += dossier["match_score"]
    
    avg_score = total_score / len(dossiers) if dossiers else 0.0
    
    return {
        "total": len(dossiers),
        "by_tier": by_tier,
        "with_llm": with_llm,
        "avg_score": round(avg_score, 3)
    }





